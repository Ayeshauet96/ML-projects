{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets = pd.read_csv('Tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_split_stratified(df_tweets):\n",
    "    '''\n",
    "    This function performs stratified splitting i.e ratio of classes in train and test data is kept the same while spitting.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    df_tweets : dataframe\n",
    "        A dataframe containing data with labels to be split.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df_tweets_train : dataframe\n",
    "        the dataframe containing train data\n",
    "     df_tweets_test : dataframe\n",
    "        the dataframe containing test data.\n",
    "\n",
    "    '''\n",
    "    df_tweets = df_tweets.sample(frac=1)\n",
    "    df_tweets.reset_index(inplace=True, drop=True)\n",
    "    df_tweets_pos = df_tweets[df_tweets.label=='positive']\n",
    "    df_tweets_neg = df_tweets[df_tweets.label=='negative']\n",
    "    df_tweets_neutral = df_tweets[df_tweets.label=='neutral']\n",
    "    pos_count = len(df_tweets_pos)\n",
    "    neg_count = len(df_tweets_neg)\n",
    "    neutral_count = len(df_tweets_neutral)\n",
    "    \n",
    "    pos_train = int(0.8 * pos_count)\n",
    "    neg_train = int(0.8 *neg_count)\n",
    "    neutral_train = int(0.8 * neutral_count)\n",
    "    \n",
    "    df_tweets_pos_train = df_tweets_pos.iloc[0:pos_train]\n",
    "    df_tweets_pos_test = df_tweets_pos.iloc[pos_train:pos_count]\n",
    "    df_tweets_neg_train = df_tweets_neg.iloc[0:neg_train]\n",
    "    df_tweets_neg_test = df_tweets_neg.iloc[neg_train:neg_count]\n",
    "    df_tweets_neutral_train = df_tweets_neutral.iloc[0:neutral_train]\n",
    "    df_tweets_neutral_test = df_tweets_neutral.iloc[neutral_train:neutral_count]\n",
    "    \n",
    "    df_tweets_train = df_tweets_pos_train.append(df_tweets_neg_train).append(df_tweets_neutral_train)\n",
    "    df_tweets_test = df_tweets_pos_test.append(df_tweets_neg_test).append(df_tweets_neutral_test)\n",
    "    \n",
    "    return df_tweets_train, df_tweets_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(tweet):\n",
    "    '''\n",
    "    This function performs preprocessing like removing punctuation, emojis, stopwords and words whose\n",
    "    count is less than 3 since they are either joining words or are useless.\n",
    "    Arguments\n",
    "    ---------\n",
    "    tweets : str\n",
    "        A string tweet.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tweet_out : list\n",
    "          A list containing words from the tweet after preprocessing.\n",
    "\n",
    "    '''\n",
    "    tweet = tweet.encode('ascii', 'ignore').decode('ascii')\n",
    "    tweet_lower = tweet.lower()\n",
    "    punctuation_numbers = '''!()-[]{};:'\"\\|,<>./?@#$%^&*+=_—~0123456789'''\n",
    "    for x in tweet_lower:\n",
    "        if x in punctuation_numbers: \n",
    "            tweet_lower = tweet_lower.replace(x, \" \")  #remove punctuation\n",
    "    tweet_bow = tweet_lower.split()\n",
    "     # remove stopwords\n",
    "    stopwords = ['a', 'an', 'the', 'who', 'what', 'when', 'where', 'has', 'is', 'was', 'and', 'they', 'we', 'us', 'im', 'them', 'it', 'i', 'u', 'st', 'bag', 'book', 'my', 'her', 'him', 'have', 'had', 'on', 'me', 'wifi', 'ive', 'in', 'gotten', 'httptcohovuaisg', 'if', 'jfk', 'la', 'phx', 'turkish', 'cs', 'cxld', 'tkt', 'tues', 'logan', 'gong', 'hm', 'wu', 'syr', 'id', 'ri', 'sm', 'ees', 'yr', 'bw', 'bf', 'bcs', 'resched', 'abq', 'thatthis', 'ty']\n",
    "    tweet_out = []\n",
    "    for word in tweet_bow:\n",
    "        if (word not in stopwords) and (len(word)>3) and ('http' not in word) :\n",
    "            tweet_out.append(word)\n",
    "        \n",
    "    return tweet_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(df_tweets, filename):\n",
    "    '''\n",
    "    This function counts occurences of all words and removes words whose count is less than 3. It then creates a bag of words\n",
    "    representation for all tweets.\n",
    "    Arguments\n",
    "    ---------\n",
    "    df_tweets: dataframe\n",
    "        An input dataframe containing all tweets.\n",
    "    filename : str\n",
    "        A csv file name where features are stored.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df_features : dataframe\n",
    "         A dataframe containg the bag of words for all tweets.\n",
    "\n",
    "    '''\n",
    "    all_words, words_list = [], []\n",
    "    words_dict = {}\n",
    "    for i in range(0, len(df_tweets)):                        \n",
    "        tweet_bow = preprocessing(df_tweets.loc[i,'text'])\n",
    "        for word in tweet_bow:\n",
    "            all_words.append(word)\n",
    "    word_frequency = Counter(all_words).most_common()      # count occurences of all words\n",
    "    for i in range(0, len(word_frequency)):\n",
    "        if word_frequency[i][1] >= 5:                 #remove words which appear in less than 5 tweets or whose count is less than 10\n",
    "            words_list.append(word_frequency[i][0])\n",
    "    words_dict = {k: [] for k in words_list}\n",
    "    \n",
    "    for word in words_list:\n",
    "        for i in range(0, len(df_tweets)):\n",
    "            words_dict[word].append(preprocessing(df_tweets.loc[i, \"text\"]).count(word))\n",
    "    df_features = pd.DataFrame(words_dict)\n",
    "    df_features['label'] = df_tweets['airline_sentiment']\n",
    "    df_features.to_csv(filename)\n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = feature_extraction(df_tweets,'feature_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = pd.read_csv('feature_tweets.csv')\n",
    "features.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>united</th>\n",
       "      <th>flight</th>\n",
       "      <th>usairways</th>\n",
       "      <th>americanair</th>\n",
       "      <th>southwestair</th>\n",
       "      <th>jetblue</th>\n",
       "      <th>your</th>\n",
       "      <th>that</th>\n",
       "      <th>with</th>\n",
       "      <th>this</th>\n",
       "      <th>...</th>\n",
       "      <th>gain</th>\n",
       "      <th>inappropriate</th>\n",
       "      <th>selling</th>\n",
       "      <th>paypal</th>\n",
       "      <th>remains</th>\n",
       "      <th>emailing</th>\n",
       "      <th>neptune</th>\n",
       "      <th>greatservice</th>\n",
       "      <th>printed</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2515 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   united  flight  usairways  americanair  southwestair  jetblue  your  that  \\\n",
       "0       0       0          1            0             0        0     0     1   \n",
       "1       1       0          0            0             0        0     1     0   \n",
       "2       0       0          1            0             0        0     0     0   \n",
       "3       0       0          0            1             0        0     0     0   \n",
       "4       0       0          0            0             0        0     0     0   \n",
       "\n",
       "   with  this  ...  gain  inappropriate  selling  paypal  remains  emailing  \\\n",
       "0     0     0  ...     0              0        0       0        0         0   \n",
       "1     0     0  ...     0              0        0       0        0         0   \n",
       "2     0     0  ...     0              0        0       0        0         0   \n",
       "3     0     1  ...     0              0        0       0        0         0   \n",
       "4     0     0  ...     0              0        0       0        0         0   \n",
       "\n",
       "   neptune  greatservice  printed     label  \n",
       "0        0             0        0   neutral  \n",
       "1        0             0        0  positive  \n",
       "2        0             0        0  positive  \n",
       "3        0             0        0  negative  \n",
       "4        0             0        0  negative  \n",
       "\n",
       "[5 rows x 2515 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test = dataset_split_stratified(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>united</th>\n",
       "      <th>flight</th>\n",
       "      <th>usairways</th>\n",
       "      <th>americanair</th>\n",
       "      <th>southwestair</th>\n",
       "      <th>jetblue</th>\n",
       "      <th>your</th>\n",
       "      <th>that</th>\n",
       "      <th>with</th>\n",
       "      <th>this</th>\n",
       "      <th>...</th>\n",
       "      <th>gain</th>\n",
       "      <th>inappropriate</th>\n",
       "      <th>selling</th>\n",
       "      <th>paypal</th>\n",
       "      <th>remains</th>\n",
       "      <th>emailing</th>\n",
       "      <th>neptune</th>\n",
       "      <th>greatservice</th>\n",
       "      <th>printed</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2515 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    united  flight  usairways  americanair  southwestair  jetblue  your  that  \\\n",
       "16       1       0          0            0             0        0     0     0   \n",
       "31       1       0          0            0             0        0     0     0   \n",
       "49       1       1          0            0             0        0     0     0   \n",
       "67       0       0          0            0             0        1     0     0   \n",
       "69       1       0          0            0             0        0     0     0   \n",
       "\n",
       "    with  this  ...  gain  inappropriate  selling  paypal  remains  emailing  \\\n",
       "16     0     0  ...     0              0        0       0        0         0   \n",
       "31     0     0  ...     0              0        0       0        0         0   \n",
       "49     0     0  ...     0              0        0       0        0         0   \n",
       "67     0     0  ...     0              0        0       0        0         0   \n",
       "69     1     0  ...     0              0        0       0        0         0   \n",
       "\n",
       "    neptune  greatservice  printed     label  \n",
       "16        0             0        0  positive  \n",
       "31        0             0        0  positive  \n",
       "49        0             0        0  positive  \n",
       "67        0             0        0  positive  \n",
       "69        0             0        0  positive  \n",
       "\n",
       "[5 rows x 2515 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train.reset_index(inplace=True, drop=True)\n",
    "features_test.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>united</th>\n",
       "      <th>flight</th>\n",
       "      <th>usairways</th>\n",
       "      <th>americanair</th>\n",
       "      <th>southwestair</th>\n",
       "      <th>jetblue</th>\n",
       "      <th>your</th>\n",
       "      <th>that</th>\n",
       "      <th>with</th>\n",
       "      <th>this</th>\n",
       "      <th>...</th>\n",
       "      <th>gain</th>\n",
       "      <th>inappropriate</th>\n",
       "      <th>selling</th>\n",
       "      <th>paypal</th>\n",
       "      <th>remains</th>\n",
       "      <th>emailing</th>\n",
       "      <th>neptune</th>\n",
       "      <th>greatservice</th>\n",
       "      <th>printed</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2515 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   united  flight  usairways  americanair  southwestair  jetblue  your  that  \\\n",
       "0       1       0          0            0             0        0     0     0   \n",
       "1       1       0          0            0             0        0     0     0   \n",
       "2       1       1          0            0             0        0     0     0   \n",
       "3       0       0          0            0             0        1     0     0   \n",
       "4       1       0          0            0             0        0     0     0   \n",
       "\n",
       "   with  this  ...  gain  inappropriate  selling  paypal  remains  emailing  \\\n",
       "0     0     0  ...     0              0        0       0        0         0   \n",
       "1     0     0  ...     0              0        0       0        0         0   \n",
       "2     0     0  ...     0              0        0       0        0         0   \n",
       "3     0     0  ...     0              0        0       0        0         0   \n",
       "4     1     0  ...     0              0        0       0        0         0   \n",
       "\n",
       "   neptune  greatservice  printed     label  \n",
       "0        0             0        0  positive  \n",
       "1        0             0        0  positive  \n",
       "2        0             0        0  positive  \n",
       "3        0             0        0  positive  \n",
       "4        0             0        0  positive  \n",
       "\n",
       "[5 rows x 2515 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(features_train):\n",
    "    \"\"\"\n",
    "    Implements naive bayes algorithm to compute the log priors and log likelihoods for training data. \n",
    "    It also performs add-one smoothing on training data\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    features_train : dataframe\n",
    "        The bag of words representation for training data.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    log_prior : array\n",
    "        The log of priors for each class.\n",
    "        \n",
    "    log_likelihood : array\n",
    "        The log of likelihood probabilities for all words of each class.\n",
    "        \n",
    "    vocab : array\n",
    "        vocabulary of all words.\n",
    "    \n",
    "    \"\"\"\n",
    "    train_pos = features_train[features_train.label == 'positive'].drop('label', axis=1)\n",
    "    train_neg = features_train[features_train.label == 'negative'].drop('label', axis=1)\n",
    "    train_neutral = features_train[features_train.label == 'neutral'].drop('label', axis=1)\n",
    "    vocab = list(features_train.drop('label', axis=1).columns)\n",
    "    len_v = len(vocab)\n",
    "    log_prior_pos = np.log(len(train_pos)/len(features_train))\n",
    "    log_prior_neg = np.log(len(train_neg)/len(features_train))\n",
    "    log_prior_neutral = np.log(len(train_neutral)/len(features_train))\n",
    "    \n",
    "    # count the total occurence of each word, add one to each word and divide it by total occurences \n",
    "    # of all words plus the length of the vocabulary\n",
    "    log_prob_pos = np.log((np.array(train_pos.sum())+1)/(sum(train_pos.sum())+len_v))  # with add one smoothing\n",
    "    log_prob_neg = np.log((np.array(train_neg.sum())+1)/(sum(train_neg.sum())+len_v))\n",
    "    log_prob_neutral = np.log((np.array(train_neutral.sum())+1)/(sum(train_neutral.sum())+len_v))\n",
    "    log_prior = np.array([log_prior_pos, log_prior_neg, log_prior_neutral])\n",
    "    log_likelihood = np.array([list(log_prob_pos), list(log_prob_neg), list(log_prob_neutral)])\n",
    "    \n",
    "    return log_prior, log_likelihood, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, log_likelihood, log_prior):\n",
    "    \"\"\"\n",
    "    predicts the class of a particular test instance.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    x : array\n",
    "        bag of words representation for a test tweet.\n",
    "    log_prior : array\n",
    "        The log of priors for each class.\n",
    "        \n",
    "    log_likelihood : array\n",
    "        The log of likelihood probabilities for all words of each class.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    predicted_class : int\n",
    "        The class predicted by Naive Bayes for a particular tweet.\n",
    "    \n",
    "    \"\"\"\n",
    "    posterior = np.zeros(3)\n",
    "    for i in range(3):\n",
    "        # word count is multiplied with the log likelihood and added to log prior.\n",
    "        posterior[i] = sum(np.array(x)*log_likelihood[i,:])+log_prior[i]\n",
    "    predicted_class = np.argmax(posterior) + 1\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_naive_bayes(X, log_likelihood, log_prior):\n",
    "    \"\"\"\n",
    "    Tests Naive Bayes for all test instances by calling the predict function repeatedly.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    X : 2d-array\n",
    "        The input test instances of shape (m,n).\n",
    "    log_prior : array\n",
    "        The log of priors for each class.\n",
    "        \n",
    "    log_likelihood : array\n",
    "        The log of likelihood probabilities for all words of each class.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Y_predict : array\n",
    "        The class predicted by Naive Bayes for all test instances.\n",
    "    \n",
    "    \"\"\"\n",
    "    Y_predict = list()\n",
    "    m = X.shape[0]\n",
    "    for i in range(0, m):\n",
    "        Y_predict.append(predict(X[i,:], log_likelihood, log_prior))\n",
    "    return Y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(Y):\n",
    "    '''\n",
    "    This function decodes the labels.\n",
    "    Arguments\n",
    "    ---------\n",
    "    Y : array\n",
    "        The values of the function at each data point. This is a vector of\n",
    "        shape (m, k), where m is the number of training examples and k is the number of categories.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Y_d : list\n",
    "          Decoded values . 1 for \"positive\" class, 2 for \"negative\" and 3 for \"neutral\".\n",
    "\n",
    "    '''\n",
    "    Y_d = []\n",
    "    for i in range(0, len(Y)):\n",
    "        if Y[i] == 'positive':\n",
    "            Y_d.append(1)\n",
    "        elif Y[i] == 'negative':\n",
    "            Y_d.append(2)\n",
    "        else:\n",
    "            Y_d.append(3)\n",
    "    return Y_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(actual_values, predicted_values):\n",
    "    '''\n",
    "    Generates confusion matrix for classification evaluation.\n",
    "    Arguments\n",
    "    ---------\n",
    "    actual_values : array\n",
    "        The actual decoded labels of test data: 1 for \"positive\", 2 for \"negative\" and 3 for \"neutral\".\n",
    "        \n",
    "    predicted_values : array\n",
    "        The predicted decoded labels of test data.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    conf_matrix : 2d array\n",
    "        The confusion matrix\n",
    "    \n",
    "\n",
    "    '''\n",
    "    conf_matrix = np.zeros((3,3))\n",
    "    for i in range(0, len(actual_values)):\n",
    "        if actual_values[i] == predicted_values[i]:\n",
    "            if actual_values[i] == 1:\n",
    "                conf_matrix[0,0] = conf_matrix[0,0] + 1\n",
    "            if actual_values[i] == 2:\n",
    "                conf_matrix[1,1] = conf_matrix[1,1] + 1\n",
    "            if actual_values[i] == 3:\n",
    "                conf_matrix[2,2] = conf_matrix[2,2] + 1\n",
    "        else:\n",
    "            if actual_values[i] == 1 and predicted_values[i] == 2:\n",
    "                conf_matrix[1,0] = conf_matrix[1,0] + 1\n",
    "            if actual_values[i] == 1 and predicted_values[i] == 3:\n",
    "                conf_matrix[2,0] = conf_matrix[2,0] + 1\n",
    "            if actual_values[i] == 2 and predicted_values[i] == 1:\n",
    "                conf_matrix[0,1] = conf_matrix[0,1] + 1\n",
    "            if actual_values[i] == 2 and predicted_values[i] == 3:\n",
    "                conf_matrix[2,1] = conf_matrix[2,1] + 1\n",
    "            if actual_values[i] == 3 and predicted_values[i] == 1:\n",
    "                conf_matrix[0,2] = conf_matrix[0,2] + 1\n",
    "            if actual_values[i] == 3 and predicted_values[i] == 2:\n",
    "                conf_matrix[1,2] = conf_matrix[1,2] + 1\n",
    "    return conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report(conf_matrix):\n",
    "    '''\n",
    "    Generates micro and macro average scores for classification evaluation using the confusion matrix.\n",
    "    Arguments\n",
    "    ---------\n",
    "    conf_matrix : 2d array\n",
    "        The confusion matrix\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    classification_report : dataframe\n",
    "        A dataframe containing micro and macro average precision, recall, accuracy and F1-scores.\n",
    "    \n",
    "\n",
    "    '''\n",
    "    tp_c1 = conf_matrix[0,0]\n",
    "    fp_c1 = conf_matrix[0,1] + conf_matrix[0,2]\n",
    "    fn_c1 = conf_matrix[1,0] + conf_matrix[2,0]\n",
    "    tn_c1 = conf_matrix[1,1] + conf_matrix[1,2] + conf_matrix[2,1] + conf_matrix[2,2]\n",
    "    precision_c1 = tp_c1 / (tp_c1 + fp_c1)\n",
    "    recall_c1 = tp_c1 / (tp_c1 + fn_c1)\n",
    "    acc_c1 = (tp_c1 + tn_c1) / (tp_c1 + fp_c1 + tn_c1 + fn_c1)\n",
    "    F1_score_c1 = (2 * precision_c1 * recall_c1) / (precision_c1 + recall_c1)\n",
    "    \n",
    "    tp_c2 = conf_matrix[1,1]\n",
    "    fp_c2 = conf_matrix[1,0] + conf_matrix[1,2]\n",
    "    fn_c2 = conf_matrix[0,1] + conf_matrix[2,1]\n",
    "    tn_c2 = conf_matrix[0,0] + conf_matrix[0,2] + conf_matrix[2,0] + conf_matrix[2,2]\n",
    "    precision_c2 = tp_c2 / (tp_c2 + fp_c2)\n",
    "    recall_c2 = tp_c2 / (tp_c2 + fn_c2)\n",
    "    acc_c2 = (tp_c2 + tn_c2) / (tp_c2 + fp_c2 + tn_c2 + fn_c2)\n",
    "    F1_score_c2 = (2 * precision_c2 * recall_c2) / (precision_c2 + recall_c2)\n",
    "    \n",
    "    tp_c3 = conf_matrix[2,2]\n",
    "    fp_c3 = conf_matrix[2,0] + conf_matrix[2,1]\n",
    "    fn_c3 = conf_matrix[0,2] + conf_matrix[1,2]\n",
    "    tn_c3 = conf_matrix[0,0] + conf_matrix[0,1] + conf_matrix[1,0] + conf_matrix[1,1]\n",
    "    precision_c3 = tp_c3 / (tp_c3 + fp_c3)\n",
    "    recall_c3 = tp_c3 / (tp_c3 + fn_c3)\n",
    "    acc_c3 = (tp_c3 + tn_c3) / (tp_c3 + fp_c3 + tn_c3 + fn_c3)\n",
    "    F1_score_c3 = (2 * precision_c3 * recall_c3) / (precision_c3 + recall_c3)\n",
    "    \n",
    "    \n",
    "    macro_prec = (precision_c1 + precision_c2 + precision_c3) / 3\n",
    "    macro_recall = (recall_c1 + recall_c2 + recall_c3) / 3\n",
    "    macro_acc = (acc_c1 + acc_c2 + acc_c3) / 3\n",
    "    macro_F1 = (F1_score_c1 + F1_score_c2 + F1_score_c3) / 3\n",
    "    \n",
    "    micro_prec = (tp_c1 + tp_c2 + tp_c3) / (tp_c1 + tp_c2 + tp_c3 + fp_c1 + fp_c2 + fp_c3)\n",
    "    micro_recall = (tp_c1 + tp_c2 + tp_c3) / (tp_c1 + tp_c2 + tp_c3 + fn_c1 + fn_c2 + fn_c3)\n",
    "    micro_acc = (tp_c1 + tp_c2 + tp_c3 + tn_c1 + tn_c2 + tn_c3) / (tp_c1 + tp_c2 + tp_c3 + tn_c1 + tn_c2 + tn_c3 + fp_c1 + fp_c2 + fp_c3 + fn_c1 + fn_c2 + fn_c3)\n",
    "    micro_F1 = (2 * micro_prec * micro_recall) / (micro_prec + micro_recall)\n",
    "    \n",
    "    data = np.array([[macro_prec, macro_recall, macro_acc, macro_F1], [micro_prec, micro_recall, micro_acc, micro_F1]])\n",
    "    classification_report = pd.DataFrame(data, columns = ['precision', 'recall', 'accuracy', 'F1_score'], index=['macro_average', 'micro_avg'])\n",
    "    return classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_prior, log_likelihood, vocab = train_naive_bayes(features_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(features_test.drop(['label'], axis=1))\n",
    "Y_test = np.array(features_test[['label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predict = test_naive_bayes(X_test, log_likelihood, log_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = decode(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(Y_test, Y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 322.,   77.,   62.],\n",
       "       [  91., 1593.,  231.],\n",
       "       [  60.,  166.,  327.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_report = classification_report(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>F1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro_average</th>\n",
       "      <td>0.707218</td>\n",
       "      <td>0.691943</td>\n",
       "      <td>0.843633</td>\n",
       "      <td>0.698809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>micro_avg</th>\n",
       "      <td>0.765449</td>\n",
       "      <td>0.765449</td>\n",
       "      <td>0.843633</td>\n",
       "      <td>0.765449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               precision    recall  accuracy  F1_score\n",
       "macro_average   0.707218  0.691943  0.843633  0.698809\n",
       "micro_avg       0.765449  0.765449  0.843633  0.765449"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
